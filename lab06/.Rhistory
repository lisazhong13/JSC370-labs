knitr::opts_chunk$set(include  = TRUE)
table(is.na(abstracts))
abstracts <- str_extract(pub_char_list, "<Abstract>(\\n|.)+</Abstract>")
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")
# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/div[1]/h3/span")
# Turning it into text
counts <- as.character(counts)
# Extracting the data using regex
stringr::str_extract(counts, "[0-9,]+")
library(httr)
query_ids <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
query = list(
db = "pubmed",
term = "covid19 toronto",
retmax = 300
) # space in term means search for covid 19 and toronto
)
# Extracting the content of the response of GET
ids <- httr::content(query_ids)
# Turn the result into a character vector
ids <- as.character(ids)
# Find all the ids
ids <- stringr::str_extract_all(ids, "<Id>[0-9]+</Id>\n")[[1]]
# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "<Id>|</Id>\n")
publications <- GET(
url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
query = list(
db = "pubmed",
id = paste(ids, collapse = ","), # each id is connected with comma now
retmax = 300,
rettype = "abstract"
)
)
# Turning the output into character vector
publications <- httr::content(publications)
publications_txt <- as.character(publications)
library(stringr)
institution <- str_extract_all(
publications_txt,
"University\\sof\\s+[[:alpha:]]+|[[:alpha:]]+\\s+Institute\\sof\\s+[[:alpha:]]+" #double slash as it is under quotation mark
)
institution <- unlist(institution)
as.data.frame(table(institution))
schools_and_deps <- str_extract_all(
publications_txt,
"School\\sof\\s+[[:alpha:]]+|Department\\sof\\s+[[:alpha:]]+"
)
as.data.frame(table(schools_and_deps))
pub_char_list <- xml2::xml_children(publications)
pub_char_list <- sapply(pub_char_list, as.character)
abstracts <- str_extract(pub_char_list, "<Abstract>(\\n|.)+</Abstract>")
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]]+>")
abstracts <- str_remove_all(abstracts, "\\s+")
table(is.na(abstracts))
titles <- str_extract(pub_char_list, "<ArticleTitle>(\\n|.)+</ArticleTitle>")
titles <- str_remove_all(titles, "</?[[:alnum:]]+>")
titles <- str_remove_all(titles, "\\s+")
table(is.na(titles))
database <- data.frame(PubMedId = ids,
Title = titles,
Abstract = abstracts)
knitr::kable(database)
